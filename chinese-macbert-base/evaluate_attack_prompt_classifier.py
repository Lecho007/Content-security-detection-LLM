import json
from sklearn.metrics import classification_report, confusion_matrix
from collections import Counter

"""
è¯„ä¼°è„šæœ¬ï¼ˆå‡çº§ç‰ˆï¼‰
âœ… å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰
âœ… æ¯ä¸ªç±»åˆ«çš„ Precision / Recall / F1ï¼ˆå« zero_division å¤„ç†ï¼‰
âœ… æ”¯æŒä¸­æ–‡æ ‡ç­¾åæ˜¾ç¤ºï¼ˆå¦‚æœä½ æœ‰ label_mapï¼‰
âœ… è‡ªåŠ¨è®¡ç®—å®å¹³å‡ï¼ˆMacroï¼‰å’ŒåŠ æƒå¹³å‡ï¼ˆWeightedï¼‰
âœ… è¾“å‡ºåˆ†ç±»æŠ¥å‘Šå’Œæ··æ·†çŸ©é˜µï¼ˆæ–‡å­—ç‰ˆï¼‰
âœ… æ˜¾ç¤ºå“ªäº›æ ‡ç­¾æœªè¢«æ¨¡å‹é¢„æµ‹åˆ°
"""

# æ–‡ä»¶è·¯å¾„
GROUND_TRUTH_FILE = "data/test_data.jsonl"     # â† çœŸå®æ ‡ç­¾æ–‡ä»¶
PREDICTION_FILE = "data/inference_output.jsonl"      # â† æ¨ç†ç»“æœæ–‡ä»¶

# æ ‡ç­¾åæ˜ å°„ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
id2label = {
    0: "è¿æ³•çŠ¯ç½ª", 1: "ææ€–ä¸»ä¹‰", 2: "æ­§è§†åè§", 3: "ä¾µçŠ¯æƒç›Š", 4: "åé¢è¯±å¯¼",
    5: "ç›®æ ‡åŠ«æŒ", 6: "Promptæ³„æ¼", 7: "ä¸å®‰å…¨çš„æŒ‡ä»¤ä¸»é¢˜", 8: "èµ‹äºˆè§’è‰²åå‘æŒ‡ä»¤",
    9: "å¸¦æœ‰ä¸å®‰å…¨è§‚ç‚¹çš„è¯¢é—®", 10: "åè§æ­§è§†", 11: "è„è¯ä¾®è¾±", 12: "å¿ƒç†å¥åº·",
    13: "èº«ä½“ä¼¤å®³", 14: "è´¢äº§éšç§", 15: "é“å¾·ä¼¦ç†", 16: "æ­£å¸¸æ–‡æœ¬"
}

def load_jsonl(filepath):
    data = []
    with open(filepath, "r", encoding="utf-8") as f:
        for line in f:
            data.append(json.loads(line.strip()))
    return data

def evaluate(gt_data, pred_data):
    assert len(gt_data) == len(pred_data), "âŒ æ–‡ä»¶é•¿åº¦ä¸ä¸€è‡´ï¼Œè¯·æ£€æŸ¥ï¼"

    y_true = [item["label"] for item in gt_data]
    y_pred = [item["label_id"] for item in pred_data]

    # âœ… è¾“å‡ºæœªè¢«é¢„æµ‹åˆ°çš„ç±»åˆ«
    all_labels = set(id2label.keys())
    predicted_labels = set(y_pred)
    missed_labels = all_labels - predicted_labels
    if missed_labels:
        print("\nâš ï¸ ä»¥ä¸‹ç±»åˆ«æœªåœ¨æ¨ç†ç»“æœä¸­è¢«é¢„æµ‹åˆ°ï¼š")
        for label_id in missed_labels:
            print(f"  - {label_id}: {id2label[label_id]}")

    # âœ… åˆ†ç±»æŠ¥å‘Šï¼ˆå« zero_division å¤„ç†ï¼‰
    print("\nğŸ¯ åˆ†ç±»æŠ¥å‘Šï¼ˆClassification Reportï¼‰ï¼š\n")
    print(classification_report(
        y_true, y_pred,
        labels=list(id2label.keys()),
        target_names=[id2label[i] for i in id2label],
        digits=4,
        zero_division=0
    ))

    # âœ… æ··æ·†çŸ©é˜µ
    print("\nğŸ§± æ··æ·†çŸ©é˜µï¼ˆConfusion Matrixï¼‰ï¼š")
    cm = confusion_matrix(y_true, y_pred, labels=list(id2label.keys()))
    label_list = [id2label[i] for i in id2label]
    print("\t" + "\t".join(label_list))
    for i, row in enumerate(cm):
        print(label_list[i] + "\t" + "\t".join(map(str, row)))

    # âœ… æ€»ä½“å‡†ç¡®ç‡
    correct = sum([yt == yp for yt, yp in zip(y_true, y_pred)])
    total = len(y_true)
    acc = correct / total
    print(f"\nâœ… æ€»ä½“å‡†ç¡®ç‡ (Accuracy): {acc:.2%} [{correct}/{total}]")

if __name__ == "__main__":
    gt_data = load_jsonl(GROUND_TRUTH_FILE)
    pred_data = load_jsonl(PREDICTION_FILE)
    evaluate(gt_data, pred_data)
