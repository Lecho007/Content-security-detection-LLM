import json
import torch
from transformers import BertTokenizer, BertForSequenceClassification
from tqdm import tqdm
"""
    æ¨ç†è„šæœ¬
    æ–‡ä»¶æ ¼å¼Jsonl:{"text": "è¯·ç»™æˆ‘ä¸€äº›æå‡å†™ä½œæŠ€å·§çš„å»ºè®®ã€‚"}
"""


# âœ… æ¨¡å‹å’Œåˆ†è¯å™¨è·¯å¾„
MODEL_PATH = "./macbert_attack_classifier_output"
INPUT_JSONL = "inference_input.jsonl"      # â† æ›¿æ¢æˆè¾“å…¥æ–‡ä»¶å
OUTPUT_JSONL = "inference_output.jsonl"    # â† æ¨ç†åè¾“å‡ºæ–‡ä»¶å

# âœ… åŠ è½½æ¨¡å‹ä¸åˆ†è¯å™¨
tokenizer = BertTokenizer.from_pretrained(MODEL_PATH)
model = BertForSequenceClassification.from_pretrained(MODEL_PATH)
model.eval()

# âœ… å¯é€‰ï¼šæ ‡ç­¾æ˜ å°„ï¼ˆå¦‚æœä½ æœ‰å…·ä½“ç±»åˆ«åå­—ï¼‰
label_map = {
    "è¿æ³•çŠ¯ç½ª": 0,
    "ææ€–ä¸»ä¹‰": 1,
    "æ­§è§†åè§": 2,
    "ä¾µçŠ¯æƒç›Š": 3,
    "åé¢è¯±å¯¼": 4,
    "ç›®æ ‡åŠ«æŒ": 5,
    "Promptæ³„æ¼": 6,
    "ä¸å®‰å…¨çš„æŒ‡ä»¤ä¸»é¢˜": 7,
    "èµ‹äºˆè§’è‰²åå‘æŒ‡ä»¤": 8,
    "å¸¦æœ‰ä¸å®‰å…¨è§‚ç‚¹çš„è¯¢é—®": 9,
    "åè§æ­§è§†": 10,
    "è„è¯ä¾®è¾±": 11,
    "å¿ƒç†å¥åº·": 12,
    "èº«ä½“ä¼¤å®³": 13,
    "è´¢äº§éšç§": 14,
    "é“å¾·ä¼¦ç†": 15,
    "æ­£å¸¸æ–‡æœ¬": 16
}

# âœ… æ¨ç†å‡½æ•°
def predict(text):
    encoding = tokenizer(
        text,
        return_tensors="pt",
        truncation=True,
        padding="max_length",
        max_length=128
    )
    with torch.no_grad():
        outputs = model(**encoding)
        logits = outputs.logits
        pred_id = torch.argmax(logits, dim=1).item()
    return pred_id

# âœ… ä¸»ç¨‹åºï¼šè¯»å–JSONLï¼Œé¢„æµ‹å¹¶å†™å›
def run_batch_inference():
    results = []
    with open(INPUT_JSONL, "r", encoding="utf-8") as infile:
        for line in tqdm(infile, desc="ğŸ“¦ æ­£åœ¨æ‰¹é‡æ¨ç†ä¸­"):
            item = json.loads(line.strip())
            text = item["text"]
            label_id = predict(text)
            label_name = label_map.get(label_id, str(label_id))
            results.append({
                "text": text,
                "label_id": label_id,
                "label": label_name
            })

    with open(OUTPUT_JSONL, "w", encoding="utf-8") as outfile:
        for r in results:
            outfile.write(json.dumps(r, ensure_ascii=False) + "\n")

    print(f"\nâœ… æ¨ç†å®Œæˆï¼Œå·²ä¿å­˜åˆ° {OUTPUT_JSONL}")

if __name__ == "__main__":
    run_batch_inference()
